---
Title: Competitive Facility Location with the Voronoi Game
Author: Fritz Reese
link-citations: true
...


# The Voronoi Game

This project aims to implement some algorithms in the field of Competitive
Facility Location (CFL). There are many papers on the problem itself (see
[References](#References)), but there appear to be few implementations floating
around.

# Table of contents

<!--ts-->
<!--te-->

## Background

The CFL problem, also called the Voronoi Game, is to optimally distribute
resources (facilities) assigned to different entities (players) given a customer
space and behavioral model. In this game, each player takes turns with rounds of
placing facilities in the customer space in order to service the most number of
customers possible. The problem becomes a geometric one when the criteria for
selecting a facility is related to distance. Often, we assume that a customer
will attend the closest facility, since it is most convenient.

The problem has a rich history in various domains, particularly in the
transportation and GIS world. An excellent review of the literature in its many
domains is presented by [@EISELT199344].

A good example domain is pizza delivery: consider two pizza companies, Pizza
John and Papa Hut, both of whom are competing to build stores in a geographic
region with the goal of maximzing profit. Assuming both companies offer pizza of
equal quality, with equal service, and at the same times, it is almost certain
that the customers in the region will order pizza from whichever store is
closest, to obtain their pizza soonest. At the start of the game, Pizza John may
already have 4 stores in the region when Papa Hut seeks to enter the market.
The game starts when the "second player", Papa Hut, places a new store.
Obviously Papa Hut will try to place one or more stores such that the number
of customers closer to Papa Hut stores than Pizza John stores is maximized.

If we consider the customer space in *R<sup>2</sup>* as in [@BANIK201753],
where the customer distance metric is straight-line Euclidean distance, the
answer is clearly related to the concept of Voronoi Diagrams. Consider a Voronoi
Diagram such that the center of the cells (sites) are set to the location of the
facilities (stores). Each Voronoi cell can be thought of as "owned by" the
player who owns the facility at its center. The player's "score" is defined as
the number of customers lying inside the player's Voronoi cells constructed with
the player's facilities at the sites.

[@BANIK201753] pursues this analogy and describes the obvious solution in
*R<sup>2</sup>*. Consider drawing a circle centered on a customer point such
that the radius of the circle is the distance from that customer to its nearest
facility. By definition, any other point that lies on the interior of the circle
will be closer to the customer than the original facility. Therefore, by
constructing this map with circles centered about each customer point, the
ideal region for a new facility is the region which is formed by the interior
of the most number of intersecting circles. We call this the "max-depth
intersecting region", and it is the solution in *R<sup>2</sup>* for player 2.

Before proposing the *R<sup>2</sup>* solution using circles and straight-line
Euclidean distance, [@BANIK201753] describes a simpler approximation method
which uses Manhattan distance. In the L1 norm, the fixed-distance boundary shape
is a tilted square rather than a circle. Banik shows one can rotate the
coordinate space then easily compute the max-depth region on the resulting
axis-aligned squares, resulting in an identically-aligned rectangle. Banik
refers to [@IMAI1983310] for this method. The general idea is to record
intersections of rectangles in an adjacency list using a plane sweep algorithm.
Then, compute the max clique of the resulting "connected components" graph.
In general, a graph may have up to *3<sup>n/3</sup>* maximal cliques as
described in [@DE201458]; but Imai & Asano show that due to the special
characteristics of a graph of intersecting rectangles, the solution is always
obtainable in *&Omicron;(n* log *n)* time.

This runtime is excellent, but the solution is approximate. Banik shows that
the identical solution in the L2 norm runs in *&Omicron(n<sup>2</sup>)* time.
This is not unexpected for a small problem in 2D, but can add up quite quickly
when the input consists of millions of customers. Input of that size is not
always necessary; but the input size depends on the domain.

A related and more complex problem is the player 1 solution. That is, where
should Pizza John, who is already in the market, place its first 4 stores to
minimize the maximal gain from a competitor who enters the market, assuming the
competitor will follow the player strategy outlined above? When there are no
competitor facilities, the ideal location for the first facility is the planar
center (and its extensions) described by [@MATOUSEK2000221]. However, it becomes
more complicated when both players already have facilities in the region. Banik
offers a solution for this problem in *R<sup>2</sup>*, using a similar circle
method, which runs in *&Omicron;(n<sup>8</sup>)* time.

Others propose methods outside *R<sup>2</sup>* ([@JGAA-235], [@BANIK201641],
[@DREZNER2014], [@EISELT1989231]).

## Approach

This project aims to provide a CFL implementation with realistic results and
constraints. Though the *&Omicron;(n<sup>8</sup>)* runtime of the player 1
solution is theoretically "reasonable" (it is polynomial, afterall) the bound is
likely too steep to run on a large input space (millions of customers) in a
reasonable amount of time. Furthermore, some implementation details were left
unclear from [@BANIK201753]. For these reasons and the sake of time we decided
to implement the simpler player 2 (P2) strategy of max-depth intersection
(with a few modifications).

## L1 P2 Solution

First, we implemented the player 2 solution in the L1 norm (Manhattan distance)
as described in [@IMAI1983310]. We used a range-tree approach to find each
customers' nearest facility based on [@CABELLO201099], then followed Imai &
Asano's paper using a line sweep. In the end, we avoided the special tree
structure *T* from Imai & Asano to track the depth of the intermediate regions,
as it would require manual manipulation of nodes in a custom 2-3 tree.  A
reliable 2-3 tree implementation with direct access to the internal nodes could
not be found, and we preferred to spend more time on a more realistic solution,
so we avoided creating our own 2-3 tree structure. Therefore we opted for a more
input-sensitive technique which can obtain *&Omicron;(n* log *n)* in the average
case but *&Omicron;(n<sup>2</sup>)* in the worst case, where we manually
increment the depths of inner rectangles when an encompassing rectangle is
inserted. The code for this is found in `src/maxrect.{cc,h}` from the `MaxRect`
class.

The results of this method are mixed. For small enough input sets it can provide
a reasonably accurate solution, but for larger data sets the solution can be
significantly worse than ideal.

After implementing the L1 solution with mixed results (the L1 solution can be
significantly off from the L2 solution) we decided to take a step back and look
at a more realistic method.

## Time-based P2 solution

First, we reconsidered the idea of straight-line distance as a customer choice
model. We realized that a distance metric is actually just an approximation of
*time*, which most directly represents the customers' selection criteria (think
again of the pizza example). To realize this, we replaced the concepts of
distance in the max-depth with time.

There are two main requirements which change significantly when replacing
distance with time: first we need to identify the nearest facility *in time* for
every customer; second we need to identify a shape which defines a fixed-*time*
boundary isomorphic to the circles of L2 and squares of L1.

Both data are actually readily available for real-world geographic locations
through services such as [@OpenStreetMap] and [@TravelTimePlatform]. The latter
supports exactly the queries described above, but only through an online API.
Since we want to avoid web queries during active runs of a CPU-intensive
geometric algorithm, we decided to take as input a quantized cache of this data
for the query points. Each customer is input to the program as a combination
point and list of a fixed number of rings. Each ring is an *isochrome*, or a
*polygon* such that every point on the boundary of the isochrome takes a fixed
time *t* to reach from the center. Each round of the game, the max-depth
algorithm will request (1) the travel time from each customer to its nearest
facility, and (2) an isochrome matching that travel time centered at each
customer. To produce these we linearly interpolate between the known fixed rings
according to the Euclidean distance between the facility point and its nearest
two rings, or between the smallest ring and the center point. Past the end of
all known rings we extrapolate similarly.

It is possible to increase the accuracy of the algorithm by writing a tool to
query travel time offline, for example using an [@OpenStreetMap] database or
ArcGIS. Another improvement would be to write a script to prefetch actual data
from [@TravelTimePlatform] -- for now, the only data tested with is randomly
generated by the helper script [`generate.py`](scripts/generate.py).

Following the [@IMAI1983310] algorithm, the algorithm can be broken into two
main parts: the [plane sweep](#plane-sweep) and
[depth detection](#max-depth-calculation).

The idea is that the maximal-depth region formed by the most number of
intersecting polygons (or triangles) will be a solution isomorphic to the
maximal intersecting number of squares or circles. Unlike Banik's solution with
circles, however, we believe we can compute the solution in an average
*&Omicron;(n* log *n)* time.

### Plane Sweep

First we need to detect the intersections of the triangles, as we would with
squares or circles. But the plane sweep algorithm to detect intersections must
be slightly different when using isochromes instead of circles or rectangles.

First, we require any continuous isochromes to be discretized into polygons.
Then, to simplify the intersection algorithm, we decompose the polygons into
triangles, and perform a plane sweep on the arrangement of the edges of the
triangles to compute all line segment intersections using the classical plane
sweep algorithm.

Let's first review the classical plane sweep approach for segment intersection.
We maintain the event queue *Q*, the sweep status *T*, and the sweep line *L*.

*Q* is a priority queue containing events, which are either endpoint events
(endpoints of the input segments) or intersection events (points where segments
intersect). The queue is initialized with all endpoints of the input segments.
Event points are visited in order of descending *y* coordinate. At each event we
draw the sweep line *L* at the same *y* value as the event point.
*T* is a binary search tree that stores references to all segments which
intersect *L* sorted by the *x* coordinate at which each segment intersects *L*.
Note that the event points are sorted lexicographically, so all points at the
same *y* coordinate are visited in order of increasing *x* coordinate.

The fundamental observation the drives the algorithm is that for segments to
intersect, their *y* intervals and *x* intervals have to overlap. By restricting
the status tree *T* to segments that intersect *L*, we know their *y* intervals
overlap. Then by sorting *T* by *x* coordinate of all segments at each *L*, we
know immediately that only adjacent segments in *T* can possibly intersect. The
trick is that, at each intersection point formed by two segments *A* and *B*,
the positions of *A* and *B* in *T* are swapped. At this moment we can check
again whether *A* and *B* intersect the next adjacent edges in *T* and queue any
further intersection points. To maintain the invariant that *T* holds every
segment that intersects *L*, we insert a segment to *T* when we pop its top
endpoint from the queue, and remove the segment from *T* when we pop its bottom
endpoint.

There is one case in which the operation of the classical algorithm above is
unclear: many segments intersecting at one point. If instead of two segments
forming an intersection point we have several, the segments can't just "swap" in
*T* after the point of intersection. Rather, the segments forming the
intersection have to be "re-ordered" to maintain the sweep invariant: that
each segment in *T* appears in the order in which the segments are intersected
by the sweep line *L*. We just need to make sure the invariant is true before
and after each intersection point. The trick is to order by the orientation of
the line segments at the point of intersection: left-most facing segments must
come first, because they will intersect the sweep line first since *T* is
ordered by increasing *x* coordinate.

Another related consideration comes from a particular characteristic of our
input segments. Because our line segments are from triangles which form
triangulated polygons, every triangle will share edges with two other triangles.
That is, we will have many duplicate segments which appear twice (once for each
triangle) but are really the same segment. However, we can't completely collapse
the edge into a single segment because we still need to acknowledge the
intersection of any lines through both triangles separately for the max depth
calculation.

When you think about it, this isn't much different from the consideration of
multiple segments forming a single intersection point.

### Max Depth Calculation

# Shapefiles

This program reads and writes in the
[ESRI Shapefile](https://en.wikipedia.org/wiki/Shapefile) format.
This format is chosen because it is widely used in the GIS community,
and the specification is open. ESRI has published a
[whitepaper](https://www.esri.com/library/whitepapers/pdfs/shapefile.pdf)
detailing the file specification.

There are several ways to read and write these files. This project provides
some very basic Python scripts in the `scripts/` subdirectory which can be used
to generate and plot shapefile test data.

There are low-level APIs available for many languages; see for example
[shapelib](http://shapelib.maptools.org/) and [GDAL](https://www.gdal.org/) for
C/C++, or [pyshp](https://github.com/GeospatialPython/pyshp) for Python.

The easiest and most powerful way to view and create shapefiles
(especially large files) is to use the proprietary [ArcGIS](https://arcgis.com)
software. If you don't have access to ArcGIS, you can use
[GNU Octave](https://www.gnu.org/software/octave/) with the
[octave-mapping](https://octave.sourceforge.io/mapping/index.html) plugin
package. (Note this package requires `octave-geometry` and `octave-io`.)

A "shapefile" is actually a collection of several files with the same
base name and different extensions. The shape file itself ends in `.shp`,
but alongside it is usually at least `.dbf` and `.shx` files. Whenever a "path
to a shapefile" is requested, the path requested should actually the basename
common to the `.shp`, `.dbf` and `.shx` files.

# Building

The source code uses C++11 features. This means `g++ >= 4.8.5` and a functional
C++ build environment is required. If you are using `g++` versions 5.0 through
5.4, you will also need static C++ libraries (on linux, it is typically
sufficient to install `libstdc++-static`.

Additionally, development versions of the following libraries are required to
build. The versions shown are the earliest known accepted versions:

| Package  | Known Supported Versions |
| -------- | ------------------------ |
| OpenCV   | >= 2.4.5                 |
| boost    | >= 1.59.0                |
| GNU GMP  | >= 6.0.0                 |
| GNU MPFR | >= 3.1.1                 |
| Shapelib | >= 1.3.0                 |

To use the shapefile helpers in the `scripts/` subdirectory you will need:

| Package | Known Supported Versions |
| ------- | ------------------------ |
| Python  | 2.7 - 3.x                |
| pyshp   | >= 1.2.1                 |

Additionally, for `plotshp.py`, you will need `tkinter` and `matplotlib`.

# Authors

  __Fritz Reese__  
  *M.S. Computer Science*, George Mason University, 2018.

  __[Jyh-Ming Lien](https://cs.gmu.edu/~jmlien/doku.php)__  
  *Ph.D. Computer Science*, Texas A&M University, 2006.  
  Department of Computer Science  
  George Mason University

# References
